---
title: "Examples Bash"
date: 2018-12-22T10:44:48+03:00 
draft: true
description: ""
tags:
categories: bash
type: post
url:
author: "Mert Nuhoglu"
output:
  html_document:
    css: styles.css
blog: mertnuhoglu.com
resource_files:
- 
path: ~/projects/study/bash/examples_bash.Rmd
state: wip
---

## sed a sql file and run it with psql

``` bash
cd ~/BQ-data-run/datarun
sed -e 's/data_20181217/data_20181220/g' -e 's/data_20181202/data_20181219/g' concatenate_sep_data.sql > concatenate_sep_data_20181220.sql
psql -f ./concatenate_sep_data_20181220.sql
``` 

### 01. Pull all time info from log files into one file

Give relative end range:

``` R
sed -n '/proc.time/,+2 p;$q' 10_generate_bq_numbers.R.log
sed -n '/proc.time/,+2 p;$q' *.R.log 
  ##> > proc.time()
  ##>     user   system  elapsed
  ##>    0.924    0.056 1030.983
  ##> > proc.time()
  ##>     user   system  elapsed
  ##>    0.716    0.044 1383.123
``` 

## sshpass for passwordless scp and ssh 

``` bash
sshpass -p bizqualify1 scp ./$file_all root@ftp1.bizqualify.com:/home/bloomberg/
scp awsbzq:~/bizqualify_data/zoom_data_extract_20181220.csv ./log
scp awsbzq:~/BQ-data-run/log/postgresqltuner.log ../log
scp "/Users/mertnuhoglu/projects/bizqualify/data_bizqualify/BizQualify_v6_4_complete data dictionary_current_with financials__Dec 2018.xlsx" awsbzq:~/bizqualify_data/
``` 

## ftp to upload 

Use ftp to upload a file:

``` sql
lftp sftp://bizqualify:$pass@sftp.bloomberg.com  -e "put $file_all; bye"
``` 

# mount a disk/volume 

You can check which volumes have been mounted with. The following will list them all:

``` bash
sudo lsblk --output NAME,TYPE,SIZE,FSTYPE,MOUNTPOINT,LABEL
  ##> NAME    TYPE   SIZE FSTYPE MOUNTPOINT LABEL
  ##> xvda    disk     2T
  ##> └─xvda1 part     2T ext4   /          cloudimg-rootfs
  ##> xvdb    disk 152.6G ext3   /mnt
  ##> xvdc    disk 152.6G ext3
  ##> xvdf    disk   1.5T
  ##> └─xvdf1 part   750G ext4              cloudimg-rootfs
``` 

mount device to `/mnt/`

``` bash
sudo mount /dev/xvdf1 /mnt/
``` 

``` bash
df -H
  ##> Filesystem      Size  Used Avail Use% Mounted on
  ##> udev             16G     0   16G   0% /dev
  ##> tmpfs           3.2G  9.1M  3.2G   1% /run
  ##> /dev/xvda1      2.1T  883M  2.1T   1% /
  ##> tmpfs            16G     0   16G   0% /dev/shm
  ##> tmpfs           5.3M     0  5.3M   0% /run/lock
  ##> tmpfs            16G     0   16G   0% /sys/fs/cgroup
  ##> /dev/xvdf1      781G  740G   41G  95% /mnt
  ##> tmpfs           3.2G     0  3.2G   0% /run/user/1000
``` 

## format external disk 

Check volume name:

``` bash
sudo lsblk --output NAME,TYPE,SIZE,FSTYPE,MOUNTPOINT,LABEL
  ##> NAME    TYPE  SIZE FSTYPE MOUNTPOINT LABEL
  ##> xvda    disk  750G
  ##> └─xvda1 part  750G ext4   /          cloudimg-rootfs
  ##> xvdf    disk    2T
``` 

Format the disk

``` bash
sudo file -s /dev/xvdf
  ##> /dev/xvdf: data
sudo mkfs -t ext4 /dev/xvdf
``` 

# aws ec2

## get volume id and instance id 

Get volume id of `bzqdb` and instance id of `bzq02` https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-volumes.html

``` bash
aws ec2 describe-volumes --filters Name=tag:Name,Values=bzqdb | jq '.Volumes[].VolumeId'
  ##> "vol-01dbb839dedafbee9"
aws ec2 describe-instances --filters Name=tag:Name,Values=bzq02 | jq '.Reservations[].Instances[].InstanceId'
  ##> "i-027ae2359c7142343"
``` 

## create and attach an EBS disk volume to an EC2 instance

Create a disk volume (EBS)

``` bash
aws ec2 create-volume --size 2000 --region us-west-2 --availability-zone us-west-2c --volume-type gp2
``` 

Attach `bzqdb` to `bzq02`

``` bash
aws ec2 attach-volume --instance-id i-027ae2359c7142343 --volume-id vol-01dbb839dedafbee9 --device /dev/sdf
``` 

### 04.05. detach EBS volume `bzqdb` from instance `bzq02`

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-detaching-volume.html

First unmount it:

``` bash
sudo umount -d /dev/xvdf
``` 

Detach it from `bzq02`

``` bash
aws ec2 detach-volume --instance-id i-027ae2359c7142343 --volume-id vol-01dbb839dedafbee9
  ##> {
  ##>     "AttachTime": "2018-12-21T14:10:01.000Z",
  ##>     "InstanceId": "i-027ae2359c7142343",
  ##>     "VolumeId": "vol-01dbb839dedafbee9",
  ##>     "State": "detaching",
  ##>     "Device": "/dev/sdf"
  ##> }
``` 

### 04.06. new EC2 instance `bzq03`

https://docs.aws.amazon.com/cli/latest/reference/ec2/request-spot-instances.html

``` bash
aws ec2 request-spot-instances --spot-price "" --type "one-time" --launch-specification file://xxx.json
``` 

### 04.13. terminate `bzq02` and delete its volumes

``` bash
aws ec2 terminate-instances --instance-ids i-027ae2359c7142343
``` 

Delete volumes of `bzq02` https://docs.aws.amazon.com/cli/latest/reference/ec2/delete-volume.html

``` bash
aws ec2 describe-volumes --filters Name=status,Values=available | jq '.Volumes[].VolumeId'
  ##> "vol-011c509651643e1e2"
  ##> "vol-03c829218b96efaf8"
aws ec2 delete-volume --volume-id vol-011c509651643e1e2
aws ec2 delete-volume --volume-id vol-03c829218b96efaf8
``` 

### 04.14. allocate elastic ip address

What are existing elastic IP addresses?

https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-addresses.html

``` bash
aws ec2 describe-addresses | jq '.Addresses[].PublicIp'
  ##> "34.215.116.149"
``` 

Create (allocate) a new IP address if there is no existing address:

https://docs.aws.amazon.com/cli/latest/reference/ec2/allocate-address.html

``` bash
aws ec2 allocate-address
``` 

Associate IP address to `bzq03` https://docs.aws.amazon.com/cli/latest/reference/ec2/associate-address.html

``` bash
aws ec2 associate-address --instance-id i-03317e7025b6e7aaf --public-ip 34.215.116.149
  ##> {
  ##>     "AssociationId": "eipassoc-01455bc9e2ae30426"
  ##> }
``` 

### 04.10. symlink `bzq03` home dir to `bzqdb` dirs

``` bash
ln -s /data/home/bizqualify_data/ /home/ubuntu/bizqualify_data
ln -s /data/home/backup/ /home/ubuntu/backup
``` 

### 04.15. change .ssh config settings

Update `~/.ssh/config`

``` text
Host awsbzq
Hostname ec2-34-215-116-149.us-west-2.compute.amazonaws.com
User ubuntu
IdentityFile ~/.ssh/bizqualify.pem
``` 

Update `~/.ssh/known_hosts`

Delete `34.215.116.149` from it.

Now, connect again.

``` bash
ssh awsbzq
``` 

# create a new user

https://www.digitalocean.com/community/tutorials/how-to-add-and-delete-users-on-an-ubuntu-14-04-vps
https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-16-04#step-four-

``` bash
# change mertnuhoglu with your username
adduser mertnuhoglu
usermod -aG sudo mertnuhoglu
su - mertnuhoglu
mkdir ~/.ssh
chmod 700 ~/.ssh
# run on localhost
cat ~/.ssh/id_rsa.pub | ssh root@[ip] "cat >> /home/mertnuhoglu/.ssh/authorized_keys"
sudo vim /etc/ssh/sshd_config
	PermitRootLogin without-password
``` 

# install apps 

## setup docker and docker-compose

``` bash
# docker setup
# from: https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
# enter password
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo systemctl status docker
sudo usermod -aG docker ${USER}
su - ${USER}
# enter password
id -nG

# docker-compose
# from: 
sudo curl -o /usr/local/bin/docker-compose -L "https://github.com/docker/compose/releases/download/1.15.0/docker-compose-$(uname -s)-$(uname -m)"
sudo chmod +x /usr/local/bin/docker-compose
docker-compose -v
# logoff login

``` 

## setup postgres

https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-16-04

``` bash
sudo apt-get update
sudo apt-get -y install postgresql postgresql-contrib
sudo apt-get -y install postgresql-client
``` 

## setup R

https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-16-04-2

``` bash
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9
sudo add-apt-repository 'deb [arch=amd64,i386] https://cran.rstudio.com/bin/linux/ubuntu xenial/'
sudo apt-get update
sudo apt-get -y install r-base
``` 

Install R packages

``` bash
sudo apt-get -y install libpq-dev
sudo apt-get -y install libcurl4-openssl-dev
sudo -i R -e 'install.packages(c("RPostgreSQL","doMC","data.table","scales","tidyverse"), dep=TRUE)'
``` 

## setup google cloud storage cli

https://cloud.google.com/storage/docs/gsutil_install#deb

``` bash
export CLOUD_SDK_REPO="cloud-sdk-$(lsb_release -c -s)"
echo "deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
sudo apt-get update && sudo apt-get -y install google-cloud-sdk
gcloud init
# password
# you need to authenticate in your own browser using your google password
``` 

## setup common utilities

``` bash
sudo add-apt-repository ppa:aacebedo/fasd
sudo apt-get update
sudo apt-get -y install fasd

sudo apt-get -y install tmux
curl -LO https://github.com/BurntSushi/ripgrep/releases/download/0.10.0/ripgrep_0.10.0_amd64.deb
sudo dpkg -i ripgrep_0.10.0_amd64.deb
sudo apt install sshpass
sudo apt install rg
``` 

## tmux

``` bash
tmux new -s t0
tmux attach -d -t t0
``` 

send current pane to window 1

		join-pane -t :1

## logs

``` bash
# check logs
cd ~/bizqualify_log/$data_run_date
tail -f 02_ingestion.R.log
``` 

## disk usage

``` bash
# check disk usage of the system
df -H
``` 

Sizes of the directories below home directory:

``` bash
du -h $HOME | sort -rh | head
  ##> 190G    /home/ubuntu
  ##> 176G    /home/ubuntu/bizqualify_data
  ##> 98G     /home/ubuntu/bizqualify_data/raw
  ##> 81G     /home/ubuntu/bizqualify_data/raw/smarty_street/bizqualify_smarty_street
  ##> 81G     /home/ubuntu/bizqualify_data/raw/smarty_street
  ##> 14G     /home/ubuntu/bizqualify_data/clean
  ##> 11G     /home/ubuntu/BQ-data-run
  ##> 7.9G    /home/ubuntu/bizqualify_data/raw/20181202
  ##> 7.8G    /home/ubuntu/bizqualify_data/raw/20181115_v4
  ##> 6.8G    /home/ubuntu/bizqualify_data/clean/20181202
```

Total free disk space on file system:

``` r
df -H
  ##> Filesystem      Size  Used Avail Use% Mounted on
  ##> udev            136G     0  136G   0% /dev
  ##> tmpfs            28G   18M   28G   1% /run
  ##> /dev/xvda1      781G  679G  103G  87% /
  ##> tmpfs           136G  4.1k  136G   1% /dev/shm
  ##> tmpfs           5.3M     0  5.3M   0% /run/lock
  ##> tmpfs           136G     0  136G   0% /sys/fs/cgroup
  ##> tmpfs            28G     0   28G   0% /run/user/1000
```

Database size:

``` sql
SELECT d.datname AS Name,  pg_catalog.pg_get_userbyid(d.datdba) AS Owner,
    CASE WHEN pg_catalog.has_database_privilege(d.datname, 'CONNECT')
        THEN pg_catalog.pg_size_pretty(pg_catalog.pg_database_size(d.datname))
        ELSE 'No Access'
    END AS SIZE
FROM pg_catalog.pg_database d
    ORDER BY
    CASE WHEN pg_catalog.has_database_privilege(d.datname, 'CONNECT')
        THEN pg_catalog.pg_database_size(d.datname)
        ELSE NULL
    END DESC -- nulls first
    LIMIT 20;
  ##>     name    |  owner   |  size
  ##> ------------+----------+---------
  ##>  bizqualify | postgres | 438 GB
  ##>  postgres   | postgres | 7000 kB
  ##>  template1  | postgres | 6857 kB
  ##>  template0  | postgres | 6857 kB
```

And this command checks the biggest relations (tables):

``` r
SELECT nspname || '.' || relname AS "relation",
    pg_size_pretty(pg_relation_size(C.oid)) AS "size"
  FROM pg_class C
  LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)
  WHERE nspname NOT IN ('pg_catalog', 'information_schema')
  ORDER BY pg_relation_size(C.oid) DESC
  LIMIT 20;
  ##>                     relation                    |  size
  ##> ------------------------------------------------+---------
  ##>  data_20181202.clean_variables                  | 21 GB
  ##>  data_20181115.all_data                         | 17 GB
``` 

Size of schema

``` sql
CREATE OR REPLACE FUNCTION pg_schema_size(text) RETURNS BIGINT AS $$
SELECT SUM(pg_total_relation_size(quote_ident(schemaname) || '.' || quote_ident(tablename)))::BIGINT FROM pg_tables WHERE schemaname = $1
$$ LANGUAGE SQL;
SELECT pg_size_pretty(pg_schema_size('data_20181115_v3b'));
  ##>  pg_size_pretty
  ##> ----------------
  ##>  71 GB
``` 


## gsutil

``` bash
gsutil ls gs://bizqualify_all_data
``` 

make a bucket (dir)

``` bash
gsutil mb gs://bizqualify_ian_data
gsutil ls gs://bizqualify_ian_data/*
  ##> gs://bizqualify_ian_data/all_data.csv
  ##> gs://bizqualify_ian_data/industries.csv
  ##> gs://bizqualify_ian_data/sectors.csv
``` 

``` bash
gsutil cp -r gs://bizqualify_common_files/ /mnt/volume_nyc1_01/bizqualify_data/raw/common
``` 

``` bash
gsutil cp gs://bizqualify_all_data/data_${previous_data_run_date}_ts.csv .
``` 

``` bash
gsutil mv gs://bizqualify_clients/hbk gs://bizqualify_clients/hbk0
``` 

## head

``` bash
head -n 1 bq_hedge_funds_all_data_deltas_20181115.csv >> filtered.csv
``` 

``` bash
head -n 1 bq_hedge_funds_all_data_20181115.csv > filtered.csv
rg -FS "PRA" bq_hedge_funds_all_data_20181115.csv >> filtered.csv
``` 

Make sample files for them as they are too big.

``` bash
head -n 100 data_20181027_ts.csv > data_20181027_ts_sample.csv
head -n 1 data_20181001_ts_sample.csv | grep bq_company_legal_name_expanded
	##> exists
head -n 1 data_20181027_ts_sample.csv | grep bq_company_legal_name_expanded
	##> not exists
``` 

## rg

Fixed word search:

``` bash
rg -FS "4.58e" data_20181115_ts.csv
rg -vFS "IESC" filter_458e_v2.csv | wc -l # 0
``` 

Exclusion with glob pattern:

``` bash
$ rg -l -g !'*.html' lftp
bash/examples_bash.Rmd
bash/study_bash.Rmd
``` 

## bq

``` bash
bq query 'select count(*) from `bigquery-public-data.samples.shakespeare`'
``` 

Check if there is any table similar in BQ:

``` sql
SELECT * 
FROM publicdata.samples.__TABLES__
WHERE starts_with(table_id, 'bq_hedge')
```

``` bash
SELECT * FROM [bizqualify:bq_data.data_20181115_ts] WHERE bq_cusip = '69354M108' LIMIT 1000;
``` 

## other

### lftp 

``` bash
lftp sftp://username:pass@sftp.domain.com -e 'set sftp:connect-program "ssh -a -x -i /home/ubuntu/.ssh/id_rsa"'
``` 

``` bash
put florida_universe_twosigma_20180702.csv
put florida_universe_twosigma_20170818.csv
``` 

### tee

``` bash
  # pipe output to pbcopy and to stdout
echo 'hello' | tee >(pbcopy)
  ##> pipe error&output to output & file
sh datarun03.sh 2>&1 | tee datarun03.sh.log
  ##> pipe output to pbcopy and to stdout
echo 'hello' | tee >(pbcopy)
  ##> > hello
``` 

`tee` with `python`: use `-u`

``` bash
python3 -u main.py 2>&1 | tee ${log_file}
``` 

### multiline echo 

``` bash
__text="
c.NotebookApp.allow_origin = '*' #allow all origins
c.NotebookApp.ip = '0.0.0.0' # listen on all IPs
"
echo "$__text" >> /home/ubuntu/.jupyter/jupyter_notebook_config.py
``` 

#### multiline heredoc

https://stackoverflow.com/questions/23929235/multi-line-string-with-extra-space-preserved-indentation/36240082

``` bash
cat << EndOfMessage
This is line 1.
This is line 2.
Line 3.
EndOfMessage
``` 

### docker exec

``` bash
docker exec -it dentas_mongo_1 bash
``` 

### nginx

Restart

opt01: service

``` bash
service nginx start
service nginx stop
service nginx restart
service nginx reload
``` 

opt02: systemctl

``` bash
systemctl nginx start
systemctl nginx stop
``` 

### date put a timestamp 

``` bash
backup_file=${file}_$(date +%Y%m%d_%H%M%S).tar.gz
``` 

### for loop

``` bash
#!/bin/bash
for i in {1..5}
do
	echo "Welcome $i times"
done
``` 

to use command line arguments use `seq`

``` bash
for ip in $(seq $2 $3)
``` 

loop over directories:

``` bash
for d in */
do
	clip_name=${d%/*}
	mv ${clip_name}/clips/${clip_name}_silence.mp4 ./collected
done
``` 

### default value

``` bash
value=${1:-the default value}
``` 

### time elapsed 

https://stackoverflow.com/questions/16908084/bash-script-to-calculate-time-elapsed

``` bash
	SECONDS=0
	...
	echo "Time seconds: $SECONDS"
``` 

### ssh key

step 01: generate a ssh key:

``` bash
# ssh key
ssh-keygen -t rsa -b 4096 -C "mert.nuhoglu@gmail.com"
  ##> /home/ubuntu/.ssh/id_rsa_bitbucket
eval "$(ssh-agent -s)"
ssh-add ~/.ssh/id_rsa_bitbucket
``` 

step 02: add this key to repository: 

opt01: github

Follow https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/


``` bash
vim ~/.ssh/id_rsa.pub
  ##> copy paste public key here:
  ##> github > avatar > settings > ssh keys > paste id_rsa.pub
``` 

opt02: bitbucket

``` bash
  ##> https://confluence.atlassian.com/bitbucket/set-up-an-ssh-key-728138079.html#SetupanSSHkey-ssh2
  ##> copy public key
vim ~/.ssh/id_rsa_bitbucket.pub
  ##> avatar > bitbucket settings > ssh keys > add

``` 

test it:

``` bash
ssh -T git@github.com
ssh -T git@bitbucket.org
  ##> Permission denied (publickey).
ssh -T -i ~/.ssh/id_rsa_bitbucket git@bitbucket.org
``` 

#### multiple ssh keys

check saved keys:

``` bash
ssh-add -l
``` 

edit ssh config

``` bash
Host bitbucket.org-mertnuhoglu
	HostName bitbucket.org
	User git
	IdentityFile ~/.ssh/id_rsa_bitbucket
	IdentitiesOnly yes
``` 

``` bash
git clone git@bitbucket.org-mertnuhoglu:mertnuhoglu/pvrp_data.git
``` 

### install conda

https://docs.conda.io/en/latest/miniconda.html

``` bash
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh 
bash Miniconda3-latest-Linux-x86_64.sh
  ##> relogin
conda
python --version
``` 

### download from google drive

Follow https://www.matthuisman.nz/2019/01/download-google-drive-files-wget-curl.html

install gdrivedl

``` bash
  ##> into /usr/sbin
sudo wget -O /usr/sbin/gdrivedl 'https://f.mjh.nz/gdrivedl'
sudo chmod +x /usr/sbin/gdrivedl
  ##> into ~/bin
sudo wget -O ~/bin/gdrivedl 'https://f.mjh.nz/gdrivedl'
sudo chmod +x ~/bin/gdrivedl
``` 

use it 

``` bash
gdrivedl https://drive.google.com/open?id=1sNhrr2u6n48vb5xuOe8P9pTayojQoOc_
gdrivedl https://drive.google.com/file/d/1sNhrr2u6n48vb5xuOe8P9pTayojQoOc_/view?usp=sharing
gdrivedl 1sNhrr2u6n48vb5xuOe8P9pTayojQoOc_
``` 

### printf current directory
 
``` bash
printf %"s" $PWD "/test"
  ##> /Users/mertnuhoglu/projects/study/r/test
printf %"s " hello world
  ##> hello world
printf %"s2" hello world
  ##> hello2world2
``` 

### ffmpeg

``` bash
ffprobe -i ${input} 2>&1 | rg eng | rg Stream | rg Audio
``` 

``` bash
	ffmpeg -i "${input}" \
		-map 0:0 -map 0:${stream} \
		-c:v libx264 -crf 23 -vf "scale=320:240" \
		-c:a aac -q:a 32 -filter:a "volume=${VOLUME_INCREASE}" \
		"${output_mp4}" 
``` 

### git init project from local non-empty directory

01: create a new repo in github

``` bash
git init
git remote add origin git@bitbucket.org:mertnuhoglu/pvrpr.git
...
git pull origin master
git push --set-upstream origin master
``` 

### shebang

``` bash
#!/bin/bash
#!/bin/sh
#!/usr/bin/env Rscript
#!/usr/bin/env python3
#!/usr/local/bin/awk -f
``` 

### range of numbers

``` bash
mv clips/split02/${clip_name}_{0002..0200}.mp4 "${anki_media}"
``` 

### test conditionals if then else: 

#### conditional: file exists

http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html

file exists:

``` bash
if [ ! -f /tmp/foo.txt  ]; then
	echo "File not found!"
fi
``` 

regex match

``` bash
      re_isanum='^[0-9]+$'                     # Regex: match whole numbers only
      if ! [[ $TIMES =~ $re_isanum ]] ; then   # if $TIMES not a whole number:
``` 

string comparison

``` bash
if [ "$NAME" = "" ]; then                      # If $NAME is an empty string,
  STRING="Hi!"                                 # our greeting is just "Hi!"
else                                           # Otherwise,
  STRING="Hi, $NAME!"                          # it is "Hi, (name)!"
fi
``` 

conditional in while

``` bash
while [ $COUNT -le $TIMES ]; do                # While counter is less than
                                               # or equal to $TIMES,
  echo $STRING                                 # print a greeting,
  let COUNT+=1                                 # then increment the counter.
done
``` 


### check linux distro version

https://www.cyberciti.biz/faq/find-linux-distribution-name-version-number/

``` bash
cat /etc/*-release
``` 

### rename files from z-lib

``` bash
rename 's/ \(z-lib.org\)//' *.*
rename 's/--\d+-\(z-lib.org\)//' *.*
``` 

### rename with sprintf

https://unix.stackexchange.com/questions/400983/how-to-use-rename-command-with-printf

use `e` flag

``` bash
rename 's/([0-9]+)/sprintf "%02d", $1/e' *
``` 

### rename files to lowercase

osx: https://stackoverflow.com/questions/7787029/how-do-i-rename-all-files-to-lowercase

``` bash
for f in *.mp4; do mv "$f" "$f.tmp"; mv "$f.tmp" "`echo $f | tr "[:upper:]" "[:lower:]"`"; done
``` 

### what is my linux version

``` bash
cat /etc/os-release
``` 

### tar compress

``` bash
tar cvzf ~/wp-content.tar.gz /home/ec2-user/wp02/wordpress/wp-content/
``` 

### rclone

``` bash
rclone config
  ##> Name                 Type
  ##> ====                 ====
  ##> aws                  s3
  ##> wasabi               s3
``` 

``` bash
rclone mkdir wasabi:mn_bizqualify_schema_backup
rclone lsd wasabi:
``` 

``` bash
rclone sync google:bizqualify_schema_backup wasabi:mn_bizqualify_schema_backup --dry-run 
rclone sync google:bizqualify_schema_backup wasabi:mn_bizqualify_schema_backup -v --log-file=log.txt
rclone lsd wasabi:mn_bizqualify_schema_backup
``` 

### open image in terminal with sixel

``` bash
./converters/img2sixel images/snake.png 
sixel photo.png
``` 

### browse files very fast: fff

``` bash
fff
f
``` 

### increment integer

``` bash
id=0
id=$((id+1))
``` 

### string formatting printf

``` bash
id=12
printf "%03d" "$id"
name=$(printf "%03d" "$id")
``` 

### getopts: options/arguments/parameters for shell scripts

Ref: 

		~/projects/study/bash/study_bash_getopts.md
		~/projects/study/bash/ex/study_bash_getopts/ex01/e01.sh

``` bash
while getopts ":n:t:" options; do
  case "${options}" in
    n)
      NAME=${OPTARG}
      ;;
    t)
      TIMES=${OPTARG}
      ;;
    :)
      echo "Error: -${OPTARG} requires an argument."
      exit_abnormal
      ;;
    *)
      exit_abnormal
      ;;
  esac
done
``` 

### shell - Get current directory name (without full path) in a Bash script - Stack Overflow

https://stackoverflow.com/questions/1371261/get-current-directory-name-without-full-path-in-a-bash-script

``` bash
result=${PWD##*/}          # to assign to a variable

printf '%s\n' "${PWD##*/}" # to print to stdout
                           # ...more robust than echo for unusual names
                           #    (consider a directory named -e or -n)

printf '%q\n' "${PWD##*/}" # to print to stdout, quoted for use as shell input
                           # ...useful to make hidden characters readable.
``` 

### function

``` bash
function convert2anki() {
	echo "generated: anki_$deck.apkg"
}
``` 

### list installed software apps and commands

opt01: built-in

https://stackoverflow.com/questions/948008/linux-command-to-list-all-available-commands-and-aliases

``` bash
compgen -c | fzf
``` 

opt02: brew cargo condo installed commands

``` bash
brew list
brew cask list
condo list
cargo install --list
``` 

### unalias run original command that aliased with same name

https://askubuntu.com/questions/525231/how-can-i-run-original-command-that-aliased-with-same-name

``` bash
\ls
'ls'
"ls"
command ls
/bin/ls
$(which ls)
``` 

### xargs delimiter newline

Ex: get info for all brew packages:

``` bash
brew list | xargs -d '\n' brew info 
``` 

``` bash
xargs -n1 -d '\n' zip "temp.zip"
  ##> 	-d delimiter is \n
  ##> 	-n1 use only one argument
``` 

### pipe after piped xargs command

Ex: I want to print only top 2 lines of brew info for each argument:

``` bash
brew list | xargs -d '\n' brew info | head -n 2
``` 

https://unix.stackexchange.com/questions/209249/piping-commands-after-a-piped-xargs

Solution:

``` bash
brew list | xargs -I {} -d '\n' sh -c "brew info {} | head -n 2"
``` 

### Which shell and terminal am I using?

https://osxdaily.com/2009/09/25/what-shell-am-i-using/

``` bash
echo $SHELL
  ##> /bin/bash

echo $TERM
  ##> xterm-kitty
``` 


