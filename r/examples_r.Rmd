---
title: "Examples R"
date: 2018-12-21T11:55:05+03:00 
draft: true
description: ""
tags:
categories: examples, R
type: post
url:
author: "Mert Nuhoglu"
output:
  html_document:
    css: styles.css
blog: mertnuhoglu.com
resource_files:
- 
path: ~/projects/study/db/examples_r.Rmd
state: wip
---

``` R
vars01 = rio::import("/Users/mertnuhoglu/projects/bizqualify/data_bizqualify/BizQualify_v6_4_complete data dictionary_current_with financials__Dec 2018.xlsx", which = 1) %>%
	select(field_name) %>%
	mutate(field_name = tolower(field_name)) 
vars_df = bind_rows(vars01, vars02, vars03, vars04)
nrow(vars_df)
vars_f = setdiff(vars, "bq_data_run_date")
length(vars_f)
``` 

tbl or dplyr with sql

``` R
sql01 = "
(SELECT *
FROM data_20181220.all_data 
WHERE bq_company_address1_zip5 = '94303'
AND bq_year = 2018
ORDER BY bq_current_employees_plan DESC
LIMIT 100)
UNION ALL
(SELECT *
FROM data_20181220.all_data 
WHERE bq_company_address1_zip5 = '10010'
AND bq_year = 2018
ORDER BY bq_current_employees_plan DESC
LIMIT 100)
UNION ALL
(SELECT *
FROM data_20181220.all_data 
WHERE bq_company_address1_zip5 = '02451'
AND bq_year = 2018
ORDER BY bq_current_employees_plan DESC
LIMIT 100)
"
d01 = tbl(con, sql(sql01)) %>% collect
``` 

``` R
d02 = d01 %>%
	select_(.dots = vars_f)
write_csv(d02, path = "~/bizqualify_data/zoom_data_extract_20181221.csv", na = "")
``` 

### 01.01.a opt01: Import into Database Using R

Filter public companies into different files because current files are too big:

``` R
library(dplyr)
library(readr)
setwd("~/bizqualify_data")
d10 = read_csv("bq_hedge_funds_all_data_20181001.csv") 
d10b = d10 %>%
	filter(!is.na(bq_ticker))
write_csv(d10b, "public_20181001.csv", na="")
``` 

Import data into database using R:

``` R
library("RPostgreSQL")
source("~/BQ-data-run/config.R")
dbWriteTable(con, c("client", "altdg_sample"), d0, row.names=F)
``` 

Note that: `dbWriteTable` doesn't write the data when it has `append=F` and the table was created already. (default value)

### 01.02. Load data from database

Load both data sets from database now:

``` R
d10 = tbl(con, sql("SELECT * FROM data_20181001.public_all_data")) %>% collect
``` 

## Run a SQL query

``` bash
dbGetQuery(con, statement = paste0("
  insert into ", data_schema, ".master_variables
  select * from ", data_schema, ".master_variables_forecast
  where source = 'ez'
"))
``` 

opt02: use dplyr::tbl()

``` bash
d0 = tbl(con, sql("
	SELECT company_ein
  FROM data_20181202.master_variables
  WHERE extract(YEAR from plan_year_end_date) = 2014 and source = 'ez'
	")) %>% collect
nrow(d0)
``` 

#### 01.01.03 Compare company_ein Between Them

``` R
d2 = setdiff(d0$company_ein, d1$company_ein)
length(d2)
  ##> [1] 112087
d3 = setdiff(d1$company_ein, d0$company_ein)
length(d3)
  ##> [1] 124030
``` 

# select and filter

Compare with 20180903 and 20180806:

``` r
c01 = read_csv("~/bizqualify_data/data_20180903_ts.csv") %>%
nrow(c01)
  ##> [1] 6521042
c02 = c01 %>%
	select(company_ein, bq_ticker, bq_company_name, bq_comp_most_recent_filing_date, bq_year)
c03 = c02 %>%
	filter(bq_comp_most_recent_filing_date >= as.Date('2017-1-1')) %>%
	filter(bq_comp_most_recent_filing_date < as.Date('2018-1-1')) 
c04 = unique(c03$company_ein)
length(c04)
	##> [1] 334453
dif_11_09 = a04[!a04 %in% c04]
length(dif_11_09)
	##> [1] 15115
dif_09_11 = c04[!c04 %in% a04]
length(dif_09_11)
	##> [1] 87989
``` 

Let's compare 08 (august) to 09 (september)

``` r
dif_09_08 = c04[!c04 %in% d04]
length(dif_09_08)
	##> [1] 922
dif_08_09 = d04[!d04 %in% c04]
length(dif_08_09)
	##> [1] 63003
``` 

# Compare Lists of Lines or Words

``` r
> d09 = readLines("0903.txt")
> d10 = readLines("1027.txt")
> setdiff(d09, d10)
[1] "bq_industry_sub_sector_code bigint" "bq_sp_500_indicator text"
> setdiff(d10, d09)
 [1] "bq_company_legal_name_expanded text"              "bq_emp_contrib_pens_amt_a_us_m bigint"
 [3] "bq_growth_emp_contrib_pens_amt_a_p bigint"        "bq_growth_emp_contrib_pens_amt_a_p_us bigint"
``` 

# Mutate column types

``` r
bd10 = bd10 %>%
	mutate(bq_revenue = as.numeric(bq_revenue)) %>%
	mutate(bq_cogs = as.numeric(bq_cogs)) %>%
	mutate(bq_gross_profit = as.integer(bq_gross_profit)) %>%
	mutate(bq_total_assets = as.numeric(bq_total_assets)) %>%
	mutate(bq_profitability_score = as.integer(bq_profitability_score)) %>%
	mutate(bq_profitability_score_i_m = as.integer(bq_profitability_score_i_m)) %>%
	mutate(bq_profitability_score_p = as.integer(bq_profitability_score_p)) %>%
	mutate(bq_profitability_score_p_us = as.integer(bq_profitability_score_p_us)) %>%
	mutate(bq_profitability_score_r = as.integer(bq_profitability_score_r)) %>%
	mutate(bq_profitability_score_r_us = as.integer(bq_profitability_score_r_us)) %>%
	mutate(bq_profitability_score_us_m = as.integer(bq_profitability_score_us_m)) 
```

## Disable Scientific Notation in write_csv

Note that, write_csv formats big numbers that end with multiple zeros in scientific notation. But scientific numbers cannot be imported into Postgresql.

To disable scientific notation, there are alternative ways:

``` r
options(scipen = 999)
write_csv(bd11[270:290,], "~/bizqualify_data/tmp.csv", na = "")
options(digits=22) 
write.csv(bd11[270:290,], "~/bizqualify_data/tmp.csv", na = "")
write.csv(bd11, "~/bizqualify_data/data_20181105_ts2.csv", na = "", row.names = F)
write.csv(bd11[1:10000,], "~/bizqualify_data/tmp.csv", na = "", row.names = F)
```

## 06. Verify that These Are Unique Really - 2. iteration

Now, 

``` R
cnt = tbl(con, sql("SELECT * FROM data_20181202.companies_non_ts")) %>% collect
length(unique(cnt$company_ein))
  ##> [1] 1149644
nrow(cnt)
  ##> [1] 6583082
``` 

Check other variables

``` R
distinct(cnt, company_ein, bq_company_legal_name) %>% nrow()
  ##> [1] 1149644
``` 

## Setup Google Drive Access using R googledrive

``` bash
install.packages("devtools")
devtools::install_github("tidyverse/googlesheets4")
library(googledrive)
library(googlesheets4)
``` 

Upload the csv and simultaneously convert to a Sheet

``` bash
(iris_tempfile <- tempfile(pattern = "iris-", fileext = ".csv"))
write.csv(iris, iris_tempfile, row.names = FALSE)
(iris_ss <- drive_upload(iris_tempfile, type = "spreadsheet"))
``` 

``` bash
## visit the new Sheet in the browser, in an interactive session!
drive_browse(iris_ss)
``` 

## other

``` R
layout <- read.csv(paste0(raw_data_dir, file), stringsAsFactors = FALSE)
``` 

Running R script from terminal

``` bash
Rscript --verbose --vanilla backtesting/backtesting.R
R --vanilla 
R --no-save --no-restore-data
R --no-save --no-restore-data -e "source('~/projects/itr/vrp_doc/study/ex/peyman_data_relations_20190522/prepare_od_table.R'); test_origin_destination_json()"
``` 

### Rmarkdown code blocks

``` {R include=F}
options(scipen = 999)
``` 

``` {R echo = F, message = F, warning = F}
library("RPostgreSQL")
library(dplyr)
library(readr)
library(knitr)

source("~/BQ-data-run/config.R")
``` 

``` {R echo=F}
sql = "
SELECT schemaname,relname,n_live_tup AS row_count
  FROM pg_stat_user_tables 
	WHERE schemaname = 'twosigma'
  ORDER BY n_live_tup DESC
"
dbGetQuery(con, sql)
``` 

``` {R echo=F}
sql = glue("
WITH unique_year_ticker AS (
	SELECT DISTINCT ON (bq_year, bq_ticker) bq_year, bq_ticker
	FROM {data_schema}.all_data
	ORDER BY bq_year, bq_ticker
)
SELECT bq_year, count(*) AS unique_bq_ticker
FROM unique_year_ticker 
GROUP BY bq_year
ORDER BY bq_year;
")
d01 = dbGetQuery(con, sql)
knitr::kable(d01)
``` 

### summary

``` R
summary(d0$percent_change_revenue)
  ##>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's
  ##>     0.00     0.00     0.00    11.69     0.00 40400.00        2
summary(d0$percent_change_employment)
  ##>      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
  ##>     0.000     0.000     0.000     5.868     0.000 28100.000
``` 

### custom summary

``` R
f1 = d0 %>%
	filter(percent_change_employment != 0)
stat = list(
  total_no_companies = nrow(d0)
	, no_change_in_employment = nrow(d0) - nrow(f1)
	, changed = nrow(f1)
	, percent_changed = (nrow(f1)/nrow(d0)*100)
)
``` 

### rmarkdown report

``` bash
file=twosigma/report_twosigma_florida_20190211.Rmd
R -e 'rmarkdown::render("'"$file"'", "md_document")'
``` 

### other

show_query id=g_10794

``` R
d01 = tbl(con, sql(s)) 
vars = c("bq_ticker", "bq_company_name", "bq_revenue")
d02 = d01 %>%
	dplyr::select(vars) 
show_query(d02)
  ##> SELECT "bq_ticker", "bq_company_name", "bq_revenue"
  ##> FROM (SELECT bq_ticker, bq_company_name, bq_revenue
  ##> FROM data_20190203.all_data) "zzzduwkcqn"
``` 

### glue id=g_10793

``` R
library(glue)
schema = "data_20190203"
s = glue("
SELECT bq_ticker, bq_company_name, bq_revenue
FROM {schema}.all_data
")
``` 

### gather id=g_10792

``` r
library(tidyverse)
d0 = data_frame(
	a = c(1,1,2,2,3),
	b = c(5,6,5,8,9)
)
gather(d0, "var", "value")
  ##>    var   value
  ##>  1 a         1
  ##>  2 a         1
``` 

``` r
d0 = data_frame(
	a = c(1,1,2,2,3),
	b = c(5,6,5,8,9),
	c = letters[1:5]
)
gather(d0, "var", "value", -c)
  ##>    c     var   value
  ##>    <chr> <chr> <dbl>
  ##>  1 a     a         1
  ##>  2 b     a         1
gather(d0, key = "var", value = "value", -c)
gather(d0, key = "var", value = "value", c(a,b))
``` 

### spread id=g_10803

``` r
s1 = tibble::tribble(
  ~id,   ~key, ~value,
  1,   "a",  2,
  1,   "b",  3,
  2,   "a",  2
  ) %>%
  tidyr::spread(key, value)
s1
#> # A tibble: 2 x 3
#>      id     a     b
#> * <dbl> <dbl> <dbl>
#> 1     1     2     3
#> 2     2     2    NA
```

### building R packages id=g_10799

opt02: building on R console (for debugging)

``` bash
cd ~/projects/yuml2data/
Rs
``` 

``` r
library(devtools)
devtools::document()
devtools::build_vignettes()
devtools::load_all()
library(magrittr)
devtools::build()
devtools::install()
``` 

opt03: building on terminal

``` bash
cd ~/projects
R CMD build yuml2data
R CMD INSTALL yuml2data_0.1.0.tar.gz
``` 

### verifications for keys id=g_10797

check uniqueness

``` r
length(unique(d0$ticker)) == nrow(d0)
  ##> TRUE
``` 

What is the duplicate `name` value?

``` r
d0 %>%
  distinct(ticker, name) %>%
  group_by(name) %>%
  summarise(n = n()) %>%
	filter(n > 1)
  ##>   name                n
  ##>   <chr>           <int>
  ##> 1 SUNDANCE ENERGY     2
d0 %>%
	filter(name == "SUNDANCE ENERGY")
  ##>   ticker name  xsector xindustry mindustry date  usd   exch  SP500  gics
  ##>   <chr>  <chr>   <int>     <int>     <int> <chr> <chr> <chr> <int> <int>
  ##> 1 SDCJF  SUND…      12       136        42 01/3… AUS   OTC       0    10
  ##> 2 SNDE   SUND…      12       136        42 01/3… USA   NSDQ      0    10
``` 

Verify that the foreign keys are valid:

		`all_data$mindustry` to `industrie$M_Industry` 
		`all_data$xsector` to `sectors$xsector`

``` r
setdiff(d0$mindustry, i0$M_Industry)
  ##> empty
setdiff(d0$xsector, i0$xsector)
  ##> empty
``` 

### descriptive stats  id=g_10798


for categorical vars:

``` r
desc_cat(d0, c('SP500'))
  ##>   var     `0`   `1`    avg    sd missing     n
  ##> 1 SP500  92.2  7.78 0.0778 0.268       0  6492
``` 

for numeric vars:

``` r
desc_num(d0, c('marketValue'))
  ##>   var           avg      sd missing     n   min   med      max
  ##> 1 marketValue 7412. 178617.       0  6492     0  254. 14186708
``` 

Check values of other categorical fields:

``` R
unique(d0$xindustry) %>% sort
  ##>   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18  19
``` 



