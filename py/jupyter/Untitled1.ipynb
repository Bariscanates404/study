{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import misaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import misaka\n",
    "import genanki\n",
    "\n",
    "from docopt import docopt\n",
    "\n",
    "VERSION = \"0.4.0\"\n",
    "\n",
    "\n",
    "def simple_hash(text):\n",
    "    \"\"\"MD5 of text, mod 2^31. Probably not a great hash function.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    h.update(text.encode(\"utf-8\"))\n",
    "    return int(h.hexdigest(), 16) % (1 << 31)\n",
    "\n",
    "\n",
    "class Card(object):\n",
    "    \"\"\"A single anki card.\"\"\"\n",
    "\n",
    "    MODEL_NAME = \"Ankdown Model\"\n",
    "    MODEL_ID = simple_hash(MODEL_NAME)\n",
    "    MODEL = genanki.Model(\n",
    "        MODEL_ID,\n",
    "        MODEL_NAME,\n",
    "        fields=[\n",
    "            {\"name\": \"Question\"},\n",
    "            {\"name\": \"Answer\"},\n",
    "            {\"name\": \"Tags\"},\n",
    "        ],\n",
    "        templates=[\n",
    "            {\n",
    "                \"name\": \"Ankdown Card\",\n",
    "                \"qfmt\": \"{{Question}}\",\n",
    "                \"afmt\": \"{{FrontSide}}<hr id='answer'>{{Answer}}\",\n",
    "            },\n",
    "        ],\n",
    "        css=\"\"\"\n",
    "        .card {\n",
    "            font-family: 'Crimson Text', 'arial';\n",
    "            font-size: 20px;\n",
    "            text-align: center;\n",
    "            color: black;\n",
    "            background-color: white;\n",
    "        }\n",
    "\n",
    "        .latex {\n",
    "            height: 0.8em;\n",
    "        }\n",
    "        \"\"\",\n",
    "    )\n",
    "\n",
    "    def __init__(self, filename=None, deckname=None):\n",
    "        self.fields = []\n",
    "        self.filename = filename\n",
    "        self.deckname = deckname\n",
    "\n",
    "    def has_data(self):\n",
    "        \"\"\"True if we have any fields filled in.\"\"\"\n",
    "        return len(self.fields) > 0\n",
    "\n",
    "    def has_front_and_back(self):\n",
    "        \"\"\"True if we have at least two fields filled in.\"\"\"\n",
    "        return len(self.fields) >= 2\n",
    "\n",
    "    def add_field(self, contents):\n",
    "        \"\"\"Add given text to a new field.\"\"\"\n",
    "        self.fields.append(contents)\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Ensure proper shape, for extraction into result formats.\"\"\"\n",
    "        if len(self.fields) > 3:\n",
    "            self.fields = self.fields[:3]\n",
    "        else:\n",
    "            while len(self.fields) < 3:\n",
    "                self.fields.append('')\n",
    "\n",
    "    def to_character_separated_line(self, separator=\"\\t\"):\n",
    "        \"\"\"Produce a tab-separated string containing the fields.\"\"\"\n",
    "        return separator.join(self.fields) + \"\\n\"\n",
    "\n",
    "    def to_genanki_note(self, deck_index=None):\n",
    "        \"\"\"Produce a genanki.Note with the specified guid.\"\"\"\n",
    "        if deck_index is None:\n",
    "            deck_index = random.randrange(1 << 30, 1 << 31)\n",
    "\n",
    "        if self.deckname is not None:\n",
    "            note_id = (simple_hash(self.deckname) + deck_index)\n",
    "        else:\n",
    "            note_id = random.randrange(1 << 30, 1 << 31)\n",
    "        return genanki.Note(model=Card.MODEL, fields=self.fields, guid=note_id)\n",
    "\n",
    "    def make_absolute_from_relative(self, filename):\n",
    "        \"\"\"Take a filename relative to the card, and make it absolute.\"\"\"\n",
    "        if os.path.isabs(filename):\n",
    "            result = filename\n",
    "        else:\n",
    "            if self.filename:\n",
    "                dirname = os.path.dirname(self.filename)\n",
    "            else:\n",
    "                dirname = \".\"\n",
    "            result = os.path.abspath(os.path.join(dirname, filename))\n",
    "        return result\n",
    "\n",
    "    def media_references(self):\n",
    "        \"\"\"Find all media references in a card\"\"\"\n",
    "        for field in self.fields:\n",
    "            # Find HTML images, at least. Maybe some other things.\n",
    "            for match in re.finditer(r'src=\"([^\"]*?)\"', field):\n",
    "                yield self.make_absolute_from_relative(match.group(1))\n",
    "            for match in re.finditer(r'\\[sound:(.*?)\\]', field):\n",
    "                yield self.make_absolute_from_relative(match.group(1))\n",
    "\n",
    "\n",
    "class DeckCollection(dict):\n",
    "    \"\"\"Defaultdict for decks, but with stored name.\"\"\"\n",
    "    def __getitem__(self, deckname):\n",
    "        if deckname not in self:\n",
    "            deck_id = random.randrange(1 << 30, 1 << 31)\n",
    "            self[deckname] = genanki.Deck(deck_id, deckname)\n",
    "        return super(DeckCollection, self).__getitem__(deckname)\n",
    "\n",
    "def sub_for_matches(text, match_iter, sentinel):\n",
    "    \"\"\"Substitute a sentinel for every match in the iterable.\n",
    "\n",
    "    Returns the substituted text and the replaced groups. This only works if\n",
    "    the matches have exactly one match group (so that match.group(1) returns\n",
    "    exactly that group).\n",
    "    \"\"\"\n",
    "    text_outside_matches = []\n",
    "    text_inside_matches = []\n",
    "    last_match_end = 0\n",
    "    for match in match_iter:\n",
    "        text_outside_matches.append(text[last_match_end:match.start()])\n",
    "        text_inside_matches.append(match.group(1))\n",
    "        last_match_end = match.end()\n",
    "    text_outside_matches.append(text[last_match_end:])\n",
    "    text_with_substitutions = sentinel.join(text_outside_matches)\n",
    "    return text_with_substitutions, text_inside_matches\n",
    "\n",
    "\n",
    "def html_from_math_and_markdown(fieldtext):\n",
    "    \"\"\"Turn a math and markdown piece of text into an HTML and Anki-math piece of text.\"\"\"\n",
    "\n",
    "    # NOTE(ben): This is the hackiest of the hacky.\n",
    "\n",
    "    # Basically, we find all the things that look like they're delimited by `$$` signs,\n",
    "    # store them, and replace them with a non-printable character that seems very\n",
    "    # unlikely to show up in anybody's code.\n",
    "    # Then we do the same for things that look like they're delimited by `$` signs, with\n",
    "    # a different nonprintable character.\n",
    "    # We run the result through the markdown compiler, hoping (well, I checked) that the\n",
    "    # nonprintable characters don't get modified or removed, and then we walk the html\n",
    "    # string and replace all the instances of the nonprintable characters with their\n",
    "    # corresponding (slightly modified) text.\n",
    "\n",
    "    # This could be slightly DRYer but it's not that bad.\n",
    "    ENV_SENTINEL = '\\1'\n",
    "    INLINE_SENTINEL = '\\2'\n",
    "\n",
    "    fieldtext_with_envs_replaced, text_inside_envs = sub_for_matches(\n",
    "        fieldtext, re.finditer(\n",
    "            r\"\\$\\$(.*?)\\$\\$\", fieldtext, re.MULTILINE | re.DOTALL), ENV_SENTINEL)\n",
    "\n",
    "    sentinel_text, text_inside_inlines = sub_for_matches(\n",
    "        fieldtext_with_envs_replaced, re.finditer(\n",
    "            r\"#latex#\\$(.*?\\S)\\$\", fieldtext_with_envs_replaced), INLINE_SENTINEL)\n",
    "            # r\"\\$(.*?\\S)\\$\", fieldtext_with_envs_replaced), INLINE_SENTINEL)\n",
    "\n",
    "    html_with_sentinels = misaka.html(sentinel_text, extensions=(\"fenced-code\",))\n",
    "\n",
    "    reconstructable_text = []\n",
    "    env_counter = 0\n",
    "    inline_counter = 0\n",
    "    for c in html_with_sentinels:\n",
    "        if c == ENV_SENTINEL:\n",
    "            reconstructable_text.append(\"[$$]\")\n",
    "            reconstructable_text.append(text_inside_envs[env_counter])\n",
    "            reconstructable_text.append(\"[/$$]\")\n",
    "            env_counter += 1\n",
    "        elif c == INLINE_SENTINEL:\n",
    "            reconstructable_text.append(\"[$]\")\n",
    "            reconstructable_text.append(text_inside_inlines[inline_counter])\n",
    "            reconstructable_text.append(\"[/$]\")\n",
    "            inline_counter += 1\n",
    "        else:\n",
    "            reconstructable_text.append(c)\n",
    "\n",
    "    return ''.join(reconstructable_text)\n",
    "\n",
    "\n",
    "def compile_field(field_lines, is_markdown):\n",
    "    \"\"\"Turn field lines into an HTML field suitable for Anki.\"\"\"\n",
    "    fieldtext = ''.join(field_lines)\n",
    "    if is_markdown:\n",
    "        result = html_from_math_and_markdown(fieldtext)\n",
    "    else:\n",
    "        result = fieldtext\n",
    "    return result.replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "def produce_cards(infile, filename=None, deckname=None):\n",
    "    \"\"\"Given the markdown and math in infile, produce the intended result cards.\"\"\"\n",
    "    if deckname is None:\n",
    "        deckname = \"Ankdown Deck\"\n",
    "    current_field_lines = []\n",
    "    current_card = Card(filename, deckname=deckname)\n",
    "    for line in infile:\n",
    "        stripped = line.strip()\n",
    "        if stripped in [\"%%\", \"---\", \"%\"]:\n",
    "            is_markdown = not current_card.has_front_and_back()\n",
    "            field = compile_field(current_field_lines, is_markdown=is_markdown)\n",
    "            current_card.add_field(field)\n",
    "            current_field_lines = []\n",
    "            if stripped in [\"%%\", \"---\"]:\n",
    "                yield current_card\n",
    "                current_card = Card(filename, deckname=deckname)\n",
    "        else:\n",
    "            current_field_lines.append(line)\n",
    "\n",
    "    if current_field_lines:\n",
    "        is_markdown = not current_card.has_front_and_back()\n",
    "        field = compile_field(current_field_lines, is_markdown=is_markdown)\n",
    "        current_card.add_field(field)\n",
    "    if current_card.has_data():\n",
    "        yield current_card\n",
    "\n",
    "\n",
    "def cards_from_dir(dirname, deckname=None):\n",
    "    \"\"\"Walk a directory and produce the cards found there, one by one.\"\"\"\n",
    "    for parent_dir, _, files in os.walk(dirname):\n",
    "        for fn in files:\n",
    "            if fn.endswith(\".md\") or fn.endswith(\".markdown\"):\n",
    "                if deckname is None:\n",
    "                    if parent_dir == \".\":\n",
    "                        # Fall back on filename if this is invoked from the\n",
    "                        # directory containing the md file\n",
    "                        this_deck_name = fn.rsplit(\".\", 1)[0]\n",
    "                    else:\n",
    "                        this_deck_name = os.path.basename(parent_dir)\n",
    "                else:\n",
    "                    this_deck_name = deckname\n",
    "                path = os.path.join(parent_dir, fn)\n",
    "                with open(os.path.join(parent_dir, fn), \"r\") as f:\n",
    "                    for card in produce_cards(f, filename=path, deckname=this_deck_name):\n",
    "                        yield card\n",
    "\n",
    "\n",
    "def cards_to_textfile(cards, outfile):\n",
    "    \"\"\"Take an iterable of cards, and turn them into a text file that Anki can read.\"\"\"\n",
    "    for card in cards:\n",
    "        outfile.write(card.to_character_separated_line())\n",
    "\n",
    "\n",
    "def cards_to_apkg(cards, output_name):\n",
    "    \"\"\"Take an iterable of the cards, and put a .apkg in a file called output_name.\"\"\"\n",
    "\n",
    "    # NOTE(ben): I'd rather have this function take an open file as a parameter\n",
    "    # than take the filename to write to, but I'm constrained by the genanki API\n",
    "\n",
    "    decks = DeckCollection()\n",
    "\n",
    "    media = set()\n",
    "    for card in cards:\n",
    "        card.finalize()\n",
    "        for media_reference in card.media_references():\n",
    "            media.add(media_reference)\n",
    "        deck_index = len(decks[card.deckname].notes)\n",
    "        decks[card.deckname].add_note(card.to_genanki_note(deck_index=deck_index))\n",
    "\n",
    "    package = genanki.Package(deck_or_decks=decks.values(), media_files=list(media))\n",
    "    package.write_to_file(output_name)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run the thing.\"\"\"\n",
    "    arguments = docopt(__doc__, version=VERSION)\n",
    "\n",
    "    in_arg = arguments['-i']\n",
    "    out_arg = arguments['-o']\n",
    "    pkg_arg = arguments['-p']\n",
    "    deck_arg = arguments['-d']\n",
    "    use_filenames_as_decknames = arguments['-D']\n",
    "    recur_dir = arguments['-r']\n",
    "\n",
    "    # Make a card iterator to produce cards one at a time\n",
    "    need_to_close_infile = False\n",
    "    if recur_dir:\n",
    "        if use_filenames_as_decknames:\n",
    "            card_iterator = cards_from_dir(recur_dir)\n",
    "        else:\n",
    "            card_iterator = cards_from_dir(recur_dir, deckname=deck_arg)\n",
    "    else:\n",
    "        if in_arg:\n",
    "            infile = open(in_arg, 'r')\n",
    "            need_to_close_infile = True\n",
    "        else:\n",
    "            infile = sys.stdin\n",
    "        card_iterator = produce_cards(infile, deckname=deck_arg)\n",
    "\n",
    "    if pkg_arg:\n",
    "        cards_to_apkg(card_iterator, pkg_arg)\n",
    "    elif out_arg:\n",
    "        with open(out_arg, 'w') as outfile:\n",
    "            return cards_to_textfile(card_iterator, outfile)\n",
    "    else:\n",
    "        return cards_to_textfile(card_iterator, sys.stdout)\n",
    "\n",
    "    if need_to_close_infile:\n",
    "        infile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_arg = \"/Users/mertnuhoglu/projects/study/pg/postgresql/anki_sql.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deck_arg = \"sql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkg_arg = \"/Users/mertnuhoglu/projects/study/pg/postgresql/anki_sql.apkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infile = open(in_arg, 'r')\n",
    "need_to_close_infile = True\n",
    "card_iterator = produce_cards(infile, deckname=deck_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cards = card_iterator\n",
    "decks = DeckCollection()\n",
    "\n",
    "media = set()\n",
    "for card in cards:\n",
    "    card.finalize()\n",
    "    for media_reference in card.media_references():\n",
    "        media.add(media_reference)\n",
    "    deck_index = len(decks[card.deckname].notes)\n",
    "    decks[card.deckname].add_note(card.to_genanki_note(deck_index=deck_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object produce_cards at 0x104af1e60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Card at 0x10474b358>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<h2>INDEX with multiple ORDER columns</h2>  <h3>Q: What is a good index with multiple ORDER keys?</h3>  <p>Ex:</p>  <pre><code class=\"language-sql\">SELECT DISTINCT ON (customer)        customer, id FROM   purchases ORDER  BY customer, id; </code></pre> \\t<h3>A:</h3>  <pre><code>      ```sql       CREATE INDEX some_idx ON purchases (customer, id);       ``` </code></pre> \\t\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card.to_character_separated_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_field(field_lines, is_markdown):\n",
    "    \"\"\"Turn field lines into an HTML field suitable for Anki.\"\"\"\n",
    "    fieldtext = \"\\n\".join(field_lines)\n",
    "    if is_markdown:\n",
    "        result = html_from_math_and_markdown(fieldtext)\n",
    "    else:\n",
    "        result = fieldtext\n",
    "    return result.replace(\" \", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "card_iterator = produce_cards(infile, deckname=deck_arg)\n",
    "cards = card_iterator\n",
    "decks = DeckCollection()\n",
    "\n",
    "media = set()\n",
    "for card in cards:\n",
    "    card.finalize()\n",
    "    for media_reference in card.media_references():\n",
    "        media.add(media_reference)\n",
    "    deck_index = len(decks[card.deckname].notes)\n",
    "    decks[card.deckname].add_note(card.to_genanki_note(deck_index=deck_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<h2>INDEX with multiple ORDER columns</h2>  <h3>Q: What is a good index with multiple ORDER keys?</h3>  <p>Ex:</p>  <pre><code class=\"language-sql\">SELECT DISTINCT ON (customer)        customer, id FROM   purchases ORDER  BY customer, id; </code></pre> \\t<h3>A:</h3>  <pre><code>      ```sql       CREATE INDEX some_idx ON purchases (customer, id);       ``` </code></pre> \\t\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card.to_character_separated_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_from_math_and_markdown(fieldtext):\n",
    "    \"\"\"Turn a math and markdown piece of text into an HTML and Anki-math piece of text.\"\"\"\n",
    "\n",
    "    # NOTE(ben): This is the hackiest of the hacky.\n",
    "\n",
    "    # Basically, we find all the things that look like they're delimited by `$$` signs,\n",
    "    # store them, and replace them with a non-printable character that seems very\n",
    "    # unlikely to show up in anybody's code.\n",
    "    # Then we do the same for things that look like they're delimited by `$` signs, with\n",
    "    # a different nonprintable character.\n",
    "    # We run the result through the markdown compiler, hoping (well, I checked) that the\n",
    "    # nonprintable characters don't get modified or removed, and then we walk the html\n",
    "    # string and replace all the instances of the nonprintable characters with their\n",
    "    # corresponding (slightly modified) text.\n",
    "\n",
    "    # This could be slightly DRYer but it's not that bad.\n",
    "    ENV_SENTINEL = '\\1'\n",
    "    INLINE_SENTINEL = '\\2'\n",
    "\n",
    "    fieldtext_with_envs_replaced, text_inside_envs = sub_for_matches(\n",
    "        fieldtext, re.finditer(\n",
    "            r\"\\$\\$(.*?)\\$\\$\", fieldtext, re.MULTILINE | re.DOTALL), ENV_SENTINEL)\n",
    "\n",
    "    sentinel_text, text_inside_inlines = sub_for_matches(\n",
    "        fieldtext_with_envs_replaced, re.finditer(\n",
    "            r\"#latex#\\$(.*?\\S)\\$\", fieldtext_with_envs_replaced), INLINE_SENTINEL)\n",
    "            # r\"\\$(.*?\\S)\\$\", fieldtext_with_envs_replaced), INLINE_SENTINEL)\n",
    "\n",
    "    html_with_sentinels = misaka.html(sentinel_text, extensions=(\"fenced-code\",))\n",
    "\n",
    "    reconstructable_text = []\n",
    "    env_counter = 0\n",
    "    inline_counter = 0\n",
    "    for c in html_with_sentinels:\n",
    "        if c == ENV_SENTINEL:\n",
    "            reconstructable_text.append(\"[$$]\")\n",
    "            reconstructable_text.append(text_inside_envs[env_counter])\n",
    "            reconstructable_text.append(\"[/$$]\")\n",
    "            env_counter += 1\n",
    "        elif c == INLINE_SENTINEL:\n",
    "            reconstructable_text.append(\"[$]\")\n",
    "            reconstructable_text.append(text_inside_inlines[inline_counter])\n",
    "            reconstructable_text.append(\"[/$]\")\n",
    "            inline_counter += 1\n",
    "        else:\n",
    "            reconstructable_text.append(c)\n",
    "\n",
    "    return '\\n'.join(reconstructable_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compile_field(field_lines, is_markdown):\n",
    "    \"\"\"Turn field lines into an HTML field suitable for Anki.\"\"\"\n",
    "    fieldtext = \"\\n\".join(field_lines)\n",
    "    if is_markdown:\n",
    "        result = html_from_math_and_markdown(fieldtext)\n",
    "    else:\n",
    "        result = fieldtext\n",
    "    return result.replace(\" \", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "card_iterator = produce_cards(infile, deckname=deck_arg)\n",
    "cards = card_iterator\n",
    "decks = DeckCollection()\n",
    "\n",
    "media = set()\n",
    "for card in cards:\n",
    "    card.finalize()\n",
    "    for media_reference in card.media_references():\n",
    "        media.add(media_reference)\n",
    "    deck_index = len(decks[card.deckname].notes)\n",
    "    decks[card.deckname].add_note(card.to_genanki_note(deck_index=deck_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<h2>INDEX with multiple ORDER columns</h2>  <h3>Q: What is a good index with multiple ORDER keys?</h3>  <p>Ex:</p>  <pre><code class=\"language-sql\">SELECT DISTINCT ON (customer)        customer, id FROM   purchases ORDER  BY customer, id; </code></pre> \\t<h3>A:</h3>  <pre><code>      ```sql       CREATE INDEX some_idx ON purchases (customer, id);       ``` </code></pre> \\t\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card.to_character_separated_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_cards(infile, filename=None, deckname=None):\n",
    "    \"\"\"Given the markdown and math in infile, produce the intended result cards.\"\"\"\n",
    "    if deckname is None:\n",
    "        deckname = \"Ankdown Deck\"\n",
    "    current_field_lines = []\n",
    "    current_card = Card(filename, deckname=deckname)\n",
    "    for line in infile:\n",
    "        stripped = line.strip()\n",
    "        if stripped in [\"%%\", \"---\", \"%\"]:\n",
    "            is_markdown = not current_card.has_front_and_back()\n",
    "            field = compile_field(current_field_lines, is_markdown=is_markdown)\n",
    "            current_card.add_field(field)\n",
    "            current_field_lines = []\n",
    "            if stripped in [\"%%\", \"---\"]:\n",
    "                return current_card\n",
    "                current_card = Card(filename, deckname=deckname)\n",
    "        else:\n",
    "            current_field_lines.append(line)\n",
    "\n",
    "    if current_field_lines:\n",
    "        is_markdown = not current_card.has_front_and_back()\n",
    "        field = compile_field(current_field_lines, is_markdown=is_markdown)\n",
    "        current_card.add_field(field)\n",
    "    if current_card.has_data():\n",
    "        return current_card\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "card_iterator = produce_cards(infile, deckname=deck_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "card_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='/Users/mertnuhoglu/projects/study/pg/postgresql/anki_sql.md' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deckname=None\n",
    "filename=None\n",
    "if deckname is None:\n",
    "    deckname = \"Ankdown Deck\"\n",
    "current_field_lines = []\n",
    "current_card = Card(filename, deckname=deckname)\n",
    "for line in infile:\n",
    "    stripped = line.strip()\n",
    "    if stripped in [\"%%\", \"---\", \"%\"]:\n",
    "        is_markdown = not current_card.has_front_and_back()\n",
    "        field = compile_field(current_field_lines, is_markdown=is_markdown)\n",
    "        current_card.add_field(field)\n",
    "        current_field_lines = []\n",
    "        if stripped in [\"%%\", \"---\"]:\n",
    "            current_card = Card(filename, deckname=deckname)\n",
    "    else:\n",
    "        current_field_lines.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_card.to_character_separated_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
